\documentclass[12pt,a4j,twoside]{jarticle}

\usepackage{gradthesis}
\usepackage{amsmath}
\usepackage[dvipdfmx]{graphicx}
\usepackage{amssymb}

\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}

\title{未定}{5}
\etitle{hoge}
\author{松本~航平}
\studentid{1W193102}
\university{早稲田大学}
\faculty{基幹理工学部}
\department{情報理工学科}
\type{卒業論文}
\nendo{2022}
\hizuke{2022/}
\advisor{菅原~俊治}

\begin{document}
\maketitle

\begin{abstract}
  本研究では,
\end{abstract}

\vspace*{1cm}\par
\section{研究背景}

\section{関連研究}

\section{モデルの定義}

\subsection{環境}

\subsection{エージェント}

\subsection{評価指標}

\section{準備}

\subsection{Adaptive meta target decision strategy (AMTDS)}
\label{subsec:AMTDS}

\subsubsection{目標決定戦略}
\label{target_strategy}

\begin{description}
  \item[Random selection (R)]\mbox{}\\
  環境全体のノード集合$V$からランダムに$v^i_{tar}$を選ぶ.

  \item[Probabilistic greedy selection (PGS)]\mbox{} \\
  環境全体のノード集合$V$内のノード$v$におけるイベント発生量の推定値$EL^i_t(v)$の上位$N_g$個のノードから,ランダムに1つ$v^i_{tar}$を選ぶ.
  この際に,学習や訪問をする$v^i_{tar}$の偏りを防ぐため,$N_g$番目のノードと$EL^i_t(v)$の値が同じノードが存在する場合,
  そのノードをすべて含めた後,その中から$v^i_{tar}$をランダムに選んでいる.

  \item[Prioritizing unvisited interval (PI)]\mbox{} \\
  環境全体のノード集合$V$内のノード$v$における訪問間隔$I^i_t(v)$の上位$N_i$個のノードから,ランダムに1つ$v^i_{tar}$を選ぶ.
  この際に,学習や訪問をする$v^i_{tar}$の偏りを防ぐため,$N_i$番目のノードと$I^i_t(v)$の値が同じノードが存在する場合,
  そのノードをすべて含めた後,その中から$v^i_{tar}$をランダムに選んでいる.
  
  \item[Balanced neighbor-preferential selection (BNPS)]\mbox{} \\
  近隣のノードにイベント発生量が多いとエージェントが判断したとき,近隣を優先的に巡回する.
  $v^i_{tar}$の決定時にエージェントの現在地$v^i_t$との距離が$d_{rad}$以下のノード集合を近領域$V^i_{area}$とする.
  ここで,$V^i_{area}$における1ステップあたりのイベント処理量の期待値$EV^i_t$は以下の式で求められる.
  \begin{equation}
    EV^i_t = \frac{\displaystyle \sum_{v \in V^i_{area}}EL^i_t(v)}{|V^i_{area}|}  
  \end{equation}
  エージェント$i$は近領域内のイベントを処理するか判断するための閾値$EV_{threshold}$と$EV^i_t$の値を比較し,
  $EV^i_t > EV_{threshold}$の間はPGSによって近領域内から$v^i_{tar}$を選ぶ.
  その後,$EV^i_t \le EV_{threshold}$となった場合,環境全体を対象とし,PGSで$v^i_{tar}$を選ぶ.
  環境全体から$v^i_{tar}$を選択した後,$V^i_{area}$を更新する.
  更新後の$V^i_{area}$の1ステップあたりのイベント処理量の期待値を$EV^i_{t+1}$とし,$EV_{threshold}$の値を以下の式に従って更新する.
  \begin{equation}
    EV_{threshold} \gets EV_{threshold} + \alpha(EV^i_{t+1} - EV_{threshold})
  \end{equation}
  ここで,$\alpha(0 < \alpha < 1)$は学習率である.また,$EV_{threshold}$の初期値は初めに$V^i_{area}$を設定した際の$EV^i_t$の値である.
\end{description}

\subsubsection{経路生成戦略}
  \label{route_strategy}
  
  \subsection{AMTDS with learning of dirt accumulation (AMTDS/LD)}
  
  \subsection{AMTDS for energy saving and cleanliness (AMTDS/ESC)}
  
  \subsubsection{要求充足の判断}
 
  \subsubsection{自己重要度評価}
  
  \subsubsection{帰還動作 (Homing)}
  
  \subsubsection{待機動作 (Pausing)}
  
  \section{提案手法}
  
  \subsection{AMTDS for energy saving under the requirement (AMTDS/ER)}
  
  \subsubsection{HomingとPausingの組み合わせ}
  
  \subsubsection{補正係数$K$の導入}
  
  \subsubsection{未来のイベント発生量の予測}
  
  \subsection{AMTDS for energy saving under the requirement with learning of  event probabilities (AMTDS/ERL)}
  
  \subsubsection{イベント発生量の予測に使用するノードの範囲の変更}
  
  \subsubsection{補正係数$K^i$の更新方法の変更}
  
  \section{評価実験}

  \subsection{実験環境}
  
  \begin{table}
    \begin{minipage}[t]{.55\textwidth}
      \centering
      \caption{エージェントに関するパラメータ}
      \begin{tabular}{lcr} \\ \hline
        種類 & パラメーター & 値 \\ \hline
        エージェント数 &  |A| & 20 \\ \hline
        バッテリ & $B^i_{max}$ & 900 \\
                   & $B^i_{drain}$ & 1 \\
                   & $k^i_{charge}$ & 3 \\ \hline
        経路生成戦略 & $d_{myopia}$ & 10 \\
                     & $k_{att}$ & 1.0 \\
                     & $k_{rover}$ & 1.2 \\ \hline
      \end{tabular}
      \label{tb:1}
    \end{minipage}
    %
    \hfill
    %
    \begin{minipage}[t]{.55\textwidth}
      \centering
      \caption{目標決定戦略のパラメーター}
      \begin{tabular}{lcrr} \\ \hline
        目標決定戦略 & パラメーター & 値 \\ \hline
        PGS & $N_g$ & 5 \\ \hline
        PI & $N_i$ & 5 \\ \hline
        BNPS & $\alpha$ & 0.1 \\
             & $d_{rad}$ & 15 \\ \hline
        AMTDS & $\alpha$ & 0.1 \\
              & $\varepsilon$ & 0.05 \\ \hline
        AMTDS/LD & $\beta$ & 0.1 \\ \hline 
      \end{tabular}
      \label{tb:2}
    \end{minipage}
    %
    \vskip\baselineskip
    %
    \begin{minipage}[t]{.55\textwidth}
      \centering
      \caption{エネルギー節約行動に関するパラメーター}
      \begin{tabular}{lcrr} \\ \hline
        種類 & パラメーター & 値 \\ \hline
        自己重要度評価 & $T_s$ & 20 \\
                       & $T_l$ & 50 \\
                       & $T_f$ & 10 \\ \hline
        Homing & $T_{check}$ & 100 \\
               & $k_{homing}$ & $\dfrac{1}{3}$ \\ \hline
        Pausing & $T_{basic}$ & 100 \\ \hline  
        AMTDS/ERL & $T_{hp}$ & 500,000 \\ \hline       
      \end{tabular}
      \label{tb:3}
    \end{minipage}
  \end{table}

  \subsection{AMTDS/ERについての実験結果}
  \label{result_ER}
  
  \subsubsection{実験1: 性能評価}
  \label{ex:ER1}
  
  \subsubsection{実験2: 環境の変化による性能の違い}
  \label{ex:ER2}

  \subsubsection{実験3: エージェント数減少による性能の変化}

  \subsubsection{実験4: $K^i$の降順にエージェント数を減少させたときの性能の変化}

  \subsection{AMTDS/ERCについての実験結果}
  \label{result_ERC}
  
  \subsubsection{実験5: 性能評価}
  \label{ex:ERC1}
  
  \subsubsection{実験6: 環境の変化による性能の違い}
  \label{ex:ERC2}  
  
  \subsubsection{実験7: エージェント数減少による性能の変化}

  \subsubsection{実験8: $K^i$の降順にエージェント数を減少させたときの性能の変化}

  \section{結論}

  \clearpage
  \bibliographystyle{junsrt}
  \bibliography{ref}

\end{document}